= Kafka Cheat Sheet
:toc:
:toc-placement!:

Here you have some useful commands for kafka.

Tested on Kafka 2.5

toc::[]

== Pre-req

First, set some kafka environment vars.

[source,bash]
----
KAFKA_BIN=/opt/kafka/bin
ZOOKEEPER_HOST=zookeeper-host:2181
BROKER_HOST=broker-host:9092
----

== Zookeeper Operations

You need to whitelist all the commands bellow. 

.zookeeper.properties
----
4lw.commands.whitelist=stat,ruok,reqs,envi,dump,conf,cons,srvr,wchs,wchc,dirs,wchp,mntr,isro
----

* If using Zookeeper Auth (SASL)

[source,bash]
----
# Zookeeper Auth
export KAFKA_OPTS="-Djava.security.auth.login.config=/tmp/jaas.conf"
----

.jass.conf
----
Client {
       org.apache.zookeeper.server.auth.DigestLoginModule required
       username="test"
       password="test";
};
----

* If using SSL/TLS on Zookeeper + SASL

[source,bash]
----
export KAFKA_OPTS="-Djava.security.auth.login.config=/tmp/jaas.conf -Dzookeeper.clientCnxnSocket=org.apache.zookeeper.ClientCnxnSocketNetty -Dzookeeper.client.secure=true -Dzookeeper.ssl.trustStore.location=/tmp/kafka.server.truststore -Dzookeeper.ssl.trustStore.password=mypass -Dzookeeper.ssl.trustStore.type=PKCS12"
----

NOTE: Remember to change your zookeeper port on the `ZOOKEEPER_HOST` if necessary

=== Get runtime conf

[source,bash]
----
echo conf | curl telnet://$ZOOKEEPER_HOST
----

=== Get runtime environments

[source,bash]
----
echo envi | curl telnet://$ZOOKEEPER_HOST
----

=== Health Check

[source,bash]
----
echo stats | curl telnet://$ZOOKEEPER_HOST

echo ruok | curl telnet://$ZOOKEEPER_HOST
----

=== Connections

[source,bash]
----
echo reqs | curl telnet://$ZOOKEEPER_HOST

echo cons | curl telnet://$ZOOKEEPER_HOST
----

=== Details of the server

[source,bash]
----
echo srvr | curl telnet://$ZOOKEEPER_HOST
----

=== Brief info about watches

[source,bash]
----
echo wchs | curl telnet://$ZOOKEEPER_HOST
----

=== Details about watches

[source,bash]
----
echo wchc | curl telnet://$ZOOKEEPER_HOST
----

=== Snapshots info

[source,bash]
----
echo dirs | curl telnet://$ZOOKEEPER_HOST
----

=== Monitoring vars

[source,bash]
----
echo mntr | curl telnet://$ZOOKEEPER_HOST
----

=== Get read-only or read-write mode

[source,bash]
----
echo isro | curl telnet://$ZOOKEEPER_HOST
----

=== Get Process

[source,bash]
----
jps | grep QuorumPeerMain
----

== Broker Operations

=== List active brokers

[source,bash]
----
$KAFKA_BIN/zookeeper-shell.sh $ZOOKEEPER_HOST ls /brokers/ids
----

=== List broker details

[source,bash]
----
$KAFKA_BIN/zookeeper-shell.sh $ZOOKEEPER_HOST ls /brokers/ids/{id}
----

=== List topics

[source,bash]
----
$KAFKA_BIN/zookeeper-shell.sh $ZOOKEEPER_HOST ls /brokers/topics
----

=== Change Broker Config

Change log cleaner threads.

[source,bash]
----
$KAFKA_BIN/kafka-configs.sh \
    --bootstrap-server $BROKER_HOST \
    --entity-type brokers \
    --entity-name <broker id> \
    --alter \
    --add-config log.cleaner.threads=2
----

=== Describe broker dynamic config

[source,bash]
----
$KAFKA_BIN/kafka-configs.sh \
    --bootstrap-server $BROKER_HOST \
    --entity-type brokers \
    --entity-name <broker id> \
    --describe
----

=== Delete broker config

[source,bash]
----
$KAFKA_BIN/kafka-configs.sh \
    --bootstrap-server $BROKER_HOST \
    --entity-type brokers \
    --entity-name <broker id> \
    --alter \
    --delete-config log.cleaner.threads
----

=== Change cluster-wide dynamic config

[source,bash]
----
$KAFKA_BIN/kafka-configs.sh \
    --bootstrap-server $BROKER_HOST \
    --entity-type brokers \
    --entity-default \
    --alter \
    --add-config log.cleaner.threads=2
----

=== Describe cluster-wide dynamic config

[source,bash]
----
$KAFKA_BIN/kafka-configs.sh \
    --bootstrap-server $BROKER_HOST \
    --entity-type brokers \
    --entity-default \
    --describe
----

=== Disable hostname verification

[source,bash]
----
$KAFKA_BIN/kafka-configs.sh \
    --bootstrap-server $BROKER_HOST \
    --entity-type brokers \
    --entity-name <broker-id> \
    --alter \
    --add-config "listener.name.internal.ssl.endpoint.identification.algorithm="
----

== Topic Operations

=== List topics using kafka-topics.sh

[source,bash]
----
$KAFKA_BIN/kafka-topics.sh \
    --list \
    --zookeeper $ZOOKEEPER_HOST
----

=== Describe topic

[source,bash]
----
$KAFKA_BIN/kafka-topics.sh \
    --zookeeper $ZOOKEEPER_HOST \
    --topic <topic_name> \
    --describe
----

[source,bash]
----
$KAFKA_BIN/kafka-configs.sh \
    --zookeeper $ZOOKEEPER_HOST \
    --entity-type topics \
    --entity-name <topic_name> \
    --describe
----

=== Move topic to another broker

==== Create json necessary

.topics-to-move.json
[source,json]
----
{"topics": [{"topic": "topic1"},
            {"topic": "topic2"}],
"version":1
}
----

==== Generate plan to move to brokers

.generate plan to move to broker 5 and 6
[source,bash]
----
$KAFKA_BIN/kafka-reassign-partitions.sh \
    --zookeeper $ZOOKEEPER_HOST \
    --topics-to-move-json-file topics-to-move.json \
    --broker-list "5,6" \
    --generate
----

NOTE: save the results from the command above to `cluster-reassignment.json`

==== Move to broker 5 and 6

.move to broker 5 and 6
[source,bash]
----
$KAFKA_BIN/kafka-reassign-partitions.sh \
    --zookeeper $ZOOKEEPER_HOST \
    --reassignment-json-file cluster-reassignment.json \
    --execute
----

==== Verify status

.verify status
[source,bash]
----
$KAFKA_BIN/kafka-reassign-partitions.sh \
    --zookeeper $ZOOKEEPER_HOST \
    --reassignment-json-file cluster-reassignment.json \
    --verify
----

=== Create topic

[source,bash]
----
$KAFKA_BIN/kafka-topics.sh \
    --create \
    --zookeeper $ZOOKEEPER_HOST \
    --replication-factor 1 \
    --partitions 1 \
    --topic <topic_name>
----

==== Create topic with config

[source,bash]
----
$KAFKA_BIN/kafka-topics.sh \
    --bootstrap-server $BROKER_HOST \
    --create \
    --topic <topic_name> \
    --partitions 1 \
    --replication-factor 1 \
    --config max.message.bytes=64000 \
    --config flush.messages=1
----

=== Alter topic

==== Alter retention time

[source,bash]
----
$KAFKA_BIN/kafka-topics.sh \
    --zookeeper $ZOOKEEPER_HOST \
    --alter \
    --topic <topic_name>\
    --config retention.ms=1000
----

==== Alter min.insync.replicas

[source,bash]
----
$KAFKA_BIN/kafka-topics.sh \
    --zookeeper $ZOOKEEPER_HOST \
    --alter \
    --topic <topic_name> \
    --config min.insync.replicas=2
----

==== Alter max.message.bytes

[source,bash]
----
$KAFKA_BIN/kafka-configs.sh \
    --zookeeper $ZOOKEEPER_HOST \
    --entity-type topics \
    --entity-name <topic_name> \
    --alter \
    --add-config max.message.bytes=128000
----

==== Delete retention time

[source,bash]
----
$KAFKA_BIN/kafka-topics.sh \
    --zookeeper $ZOOKEEPER_HOST \
    --alter \
    --topic <topic_name> \
    --delete-config retention.ms
----

[source,bash]
----
$KAFKA_BIN/kafka-configs.sh \
    --zookeeper $ZOOKEEPER_HOST \ 
    --entity-type topics \
    --entity-name <topic_name> \
    --alter \
    --delete-config retention.ms
----

=== List topics under-replicated

[source,bash]
----
$KAFKA_BIN/kafka-topics.sh \
    --zookeeper $ZOOKEEPER_HOST \
    --describe \
    --under-replicated-partitions
----

=== Delete topic

[source,bash]
----
$KAFKA_BIN/kafka-topics.sh \
    --delete \
    --zookeeper $ZOOKEEPER_HOST \
    --topic <topic_name>
----

[source,bash]
----
$KAFKA_BIN/kafka-topics.sh \
    --bootstrap-server $BROKER_HOST \
    --delete \
    --topic <topic_name>
----

=== Get earliest offset

[source,bash]
----
$KAFKA_BIN/kafka-run-class.sh \
    kafka.tools.GetOffsetShell \
    --broker-list $BROKER_HOST \
    --topic <topic_name> \
    --time -2
----

=== Get latest offset

[source,bash]
----
$KAFKA_BIN/kafka-run-class.sh \
    kafka.tools.GetOffsetShell \
    --broker-list $BROKER_HOST \
    --topic <topic_name> \
    --time -1
----

== Partition Operations

=== Add partitions

[source,bash]
----
$KAFKA_BIN/kafka-topics.sh \
    --alter \
    --topic <topic_name> \
    --partitions 8
----

=== Increase replication factor

.new-replication-factor.json
[source,json]
----
{"version":1,"partitions":[{"topic":"topic1","partition":0,"replicas":[5,6,7]}]}
----

.execute new replication factor
[source,bash]
----
$KAFKA_BIN/kafka-reassign-partitions.sh \
    --zookeeper $ZOOKEEPER_HOST \
    --reassignment-json-file new-replication-factor.json \
    --execute
----

.verify status of partition reassignment
[source,bash]
----
$KAFKA_BIN/kafka-reassign-partitions.sh \
    --zookeeper $ZOOKEEPER_HOST \
    --reassignment-json-file new-replication-factor.json \
    --verify

$KAFKA_BIN/kafka-topics.sh \
    --bootstrap-server $ZOOKEEPER_HOST \
    --topic <topic_name> \
    --describe
----

=== Reassign partitions

[source,bash]
----
$KAFKA_BIN/kafka-reassign-partitions.sh \
    --zookeeper $ZOOKEEPER_HOST \
    --reassignment-json-file increase-replication-factor.json  \
    --execute

$KAFKA_BIN/kafka-reassign-partitions.sh \
    --zookeeper $ZOOKEEPER_HOST \
    --reassignment-json-file increase-replication-factor.json  \
    --verify
----

=== List unavailable partitions

[source,bash]
----
$KAFKA_BIN/kafka-topics.sh \
    --zookeeper $ZOOKEEPER_HOST \
    --describe \
    --unavailable-partitions
----

== Consumer

=== List consumer groups

[source,bash]
----
$KAFKA_BIN/kafka-consumer-groups.sh \
    --list \
    --bootstrap-server $BROKER_HOST
----

=== Describe consumer groups

[source,bash]
----
$KAFKA_BIN/kafka-consumer-groups.sh \
    --describe \
    --group <group_id> \
    --bootstrap-server $BROKER_HOST
----

=== Delete consumer group

[source,bash]
----
$KAFKA_BIN/kafka-consumer-groups.sh \
    --bootstrap-server $BROKER_HOST \
    --delete \
    --group <group-id-1> \
    --group <group-id-2>
----

=== Active member in a consumer group

[source,bash]
----
$KAFKA_BIN/kafka-consumer-groups.sh \
    --bootstrap-server $BROKER_HOST \
    --describe \
    --group <group-id> \
    --members
----

=== Partition Assigned to each member

[source,bash]
----
$KAFKA_BIN/kafka-consumer-groups.sh \
    --bootstrap-server $BROKER_HOST \
    --describe \
    --group <group_id> \
    --members \
    --verbose
----

=== Consumer Group State

[source,bash]
----
$KAFKA_BIN/kafka-consumer-groups.sh \
    --bootstrap-server $BROKER_HOST \
    --describe \
    --group <group-id> \
    --state
----

=== Consuming message from the beginning

[source,bash]
----
$KAFKA_BIN/kafka-console-consumer.sh \
    --bootstrap-server $BROKER_HOST \
    --topic <topic_name> \
    --from-beginning
----

=== Consuming message from the end

[source,bash]
----
$KAFKA_BIN/kafka-console-consumer.sh \
    --bootstrap-server $BROKER_HOST \
    --topic <topic_name>
----

=== Read one message

[source,bash]
----
$KAFKA_BIN/kafka-console-consumer.sh \
    --bootstrap-server $BROKER_HOST \
    --topic <topic_name> \
    --max-messages 1
----

=== Read from __consumer_offsets

[source,bash]
----
$KAFKA_BIN/kafka-console-consumer.sh \
    --bootstrap-server $BROKER_HOST \
    --topic __consumer_offsets \
    --formatter 'kafka.coordinator.group.GroupMetadataManager$OffsetsMessageFormatter' \
    --max-messages 1
----

=== Describe __consumer_offsets

[source,bash]
----
$KAFKA_BIN/kafka-run-class.sh kafka.admin.ConsumerGroupCommand \
    --bootstrap-server $BROKER_HOST \
    --group <group-id> \
    --new-consumer \
    --describe
----

=== Consume using consumer group

[source,bash]
----
$KAFKA_BIN/kafka-console-consumer.sh \
    --topic <topic_name> \
    --bootstrap-server $BROKER_HOST \
    --group <group-id>
----

=== Topics to which group is subscribed

[source,bash]
----
$KAFKA_BIN/kafka-consumer-groups.sh \
    --bootstrap-server $BROKER_HOST \
    --group <group_id> \
    --describe
----

=== Reset offset

==== Reset to the latest offset

[source,bash]
----
$KAFKA_BIN/kafka-consumer-groups.sh \
    --bootstrap-server $BROKER_HOST \
    --reset-offsets \
    --group <group-id> \
    --topic topic1 \
    --to-latest
----

==== Reset offset for a consumer group in a topic

[source,bash]
----
# There are many other resetting options
# --shift-by <positive_or_negative_integer> / --to-current / --to-latest / --to-offset <offset_integer>
# --to-datetime <datetime_string> --by-duration <duration_string>
$KAFKA_BIN/kafka-consumer-groups.sh \
    --bootstrap-server $BROKER_HOST \
    --group <group_id> \
    --topic <topic_name> \
    --reset-offsets \
    --to-earliest \
    --execute
----

==== Reset offset from all consumer groups

[source,bash]
----
$KAFKA_BIN/kafka-consumer-groups.sh \
    --bootstrap-server $BROKER_HOST \
    --all-groups \
    --reset-offsets \
    --topic <topic_name> \
    --to-earliest
----

==== Forward by 2 for example

[source,bash]
----
$KAFKA_BIN/kafka-consumer-groups.sh \
    --bootstrap-server $BROKER_HOST \
    --group <groud_id> \
    --reset-offsets \
    --shift-by 2 \
    --execute \
    --topic <topic_name>
----

==== Backward by 2 for example

[source,bash]
----
$KAFKA_BIN/kafka-consumer-groups.sh \
    --bootstrap-server $BROKER_HOST \
    --group <groud_id> \
    --reset-offsets \
    --shift-by -2 \
    --execute \
    --topic <topic_name>
----

=== Describe consumer group

[source,bash]
----
$KAFKA_BIN/kafka-consumer-groups.sh \
    --bootstrap-server $BROKER_HOST \
    --describe \
    --group <group_id>
----

=== Check offset for consumer group

[source,bash]
----
$KAFKA_BIN/kafka-consumer-offset-checker.sh  \
    --zookeeper $ZOOKEEPER_HOST \
    --group <group_id> \
    --topic <topic_name>
----

== Producer

=== Send message using file

[source,bash]
----
$KAFKA_BIN/kafka-console-producer.sh \
    --broker-list $BROKER_HOST \
    --topic <topic_name> < messages.txt
----

=== Send message using standard input

[source,bash]
----
$KAFKA_BIN/kafka-console-producer \
    --broker-list $BROKER_HOST \
    --topic <topic_name>
----

=== Send message using string

[source,bash]
----
echo "My Message" | $KAFKA_BIN/kafka-console-producer.sh \
    --broker-list $BROKER_HOST \
    --topic <topic_name>
----

=== Send message using ack=all

[source,bash]
----
$KAFKA_BIN/kafka-console-producer.sh \
    --broker-list $BROKER_HOST \
    --topic <topic_name> \
    --producer-property acks=all
----

== Quotas

=== Add quota for user and client-id

[source,bash]
----
$KAFKA_BIN/kafka-configs.sh \
    --zookeeper $ZOOKEEPER_HOST \
    --alter \
    --add-config 'producer_byte_rate=1024,consumer_byte_rate=2048,request_percentage=200' \
    --entity-type users \
    --entity-name <user> \
    --entity-type clients \
    --entity-name <client-id>
----

=== Add quota for user

[source,bash]
----
$KAFKA_BIN/kafka-configs.sh \
    --zookeeper $ZOOKEEPER_HOST \
    --alter \
    --add-config 'producer_byte_rate=1024,consumer_byte_rate=2048,request_percentage=200' \
    --entity-type users \
    --entity-name <user>
----

=== Add quota for client-id

[source,bash]
----
$KAFKA_BIN/kafka-configs.sh \
    --zookeeper $ZOOKEEPER_HOST \
    --alter \
    --add-config 'producer_byte_rate=1024,consumer_byte_rate=2048,request_percentage=200' \
    --entity-type clients \
    --entity-name <client-id>
----

=== Add default client-id quota for user

[source,bash]
----
$KAFKA_BIN/kafka-configs.sh \
    --zookeeper $ZOOKEEPER_HOST \
    --alter \
    --add-config 'producer_byte_rate=1024,consumer_byte_rate=2048,request_percentage=200' \
    --entity-type users \
    --entity-name <user> \
    --entity-type clients \
    --entity-default
----

=== Add default quota for user

[source,bash]
----
$KAFKA_BIN/kafka-configs.sh \
    --zookeeper $ZOOKEEPER_HOST \
    --alter \
    --add-config 'producer_byte_rate=1024,consumer_byte_rate=2048,request_percentage=200' \
    --entity-type users \
    --entity-default
----

=== Add default quota for client-id

[source,bash]
----
$KAFKA_BIN/kafka-configs.sh \
    --zookeeper $ZOOKEEPER_HOST \
    --alter \
    --add-config 'producer_byte_rate=1024,consumer_byte_rate=2048,request_percentage=200' \
    --entity-type clients \
    --entity-default
----

=== Describe quota for user and client-id

[source,bash]
----
$KAFKA_BIN/kafka-configs.sh \
    --zookeeper $ZOOKEEPER_HOST \
    --describe \
    --entity-type users \
    --entity-name <user> \
    --entity-type clients \
    --entity-name <cliente-id>
----

=== Describe quota for a user

[source,bash]
----
$KAFKA_BIN/kafka-configs.sh \
    --zookeeper $ZOOKEEPER_HOST \
    --describe \
    --entity-type users \
    --entity-name <user>
----

=== Describe quota for a client

[source,bash]
----
$KAFKA_BIN/kafka-configs.sh \
    --zookeeper $ZOOKEEPER_HOST \
    --describe \
    --entity-type clients \
    --entity-name <client-id>
----

== ACLs

[source,bash]
----
$KAFKA_BIN/kafka-acls.sh \
    --authorizer-properties zookeeper.connect=$ZOOKEEPER_HOST \
    --add \
    --allow-principal User:Gus \
    --consumer \
    --topic <topic_name> \
    --group <group_id>
----

[source,bash]
----
$KAFKA_BIN/kafka-acls.sh
    --authorizer-properties zookeeper.connect=$ZOOKEEPER_HOST \
    --add \
    --allow-principal User:Gus \
    --producer \
    --topic <topic_name>
----

=== List topics ACLs

[source,bash]
----
$KAFKA_BIN/kafka-acls.sh \
    --authorizer-properties zookeeper.connect=$ZOOKEEPER_HOST \
    --list \
    --topic <topic_name>
----

== Mirror Maker

=== Mirror topic

[source,bash]
----
$KAFKA_BIN/kafka-mirror-maker.sh \
    --consumer.config consumer.properties \
    --producer.config producer.properties \
    --whitelist <topic_name>
----

== Delegation Token

=== Create token

[source,bash]
----
$KAFKA_BIN/kafka-delegation-tokens.sh \
    --bootstrap-server $BROKER_HOST \
    --create \
    --max-life-time-period -1 \
    --command-config client.properties \
    --renewer-principal User:<user>
----

=== Renew token

[source,bash]
----
$KAFKA_BIN/kafka-delegation-tokens.sh \
    --bootstrap-server $BROKER_HOST \
    --renew \
    --renew-time-period -1 \
    --command-config client.properties \
    --hmac ABCDEFGHIJK
----

=== Expire token

[source,bash]
----
$KAFKA_BIN/kafka-delegation-tokens.sh \
    --bootstrap-server $BROKER_HOST \
    --expire \
    --expiry-time-period -1 \
    --command-config client.properties \
    --hmac ABCDEFGHIJK
----

=== Describe token

[source,bash]
----
$KAFKA_BIN/kafka-delegation-tokens.sh \
    --bootstrap-server $BROKER_HOST \
    --describe \
    --command-config client.properties \
    --owner-principal User:<user1>
----